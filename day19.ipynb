{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advent of Code 2023\n",
    "# Day 19 Problem 1\n",
    "import re\n",
    "from collections import Counter\n",
    "import functools\n",
    "\n",
    "with open(\"aoc_19_input.txt\") as f:\n",
    "   A =  f.read().strip()\n",
    "\n",
    "# c+p test case here\n",
    "TEST = \"\"\"px{a<2006:qkq,m>2090:A,rfg}\n",
    "pv{a>1716:R,A}\n",
    "lnx{m>1548:A,A}\n",
    "rfg{s<537:gd,x>2440:R,A}\n",
    "qs{s>3448:A,lnx}\n",
    "qkq{x<1416:A,crn}\n",
    "crn{x>2662:A,R}\n",
    "in{s<1351:px,qqz}\n",
    "qqz{s>2770:qs,m<1801:hdj,R}\n",
    "gd{a>3333:R,R}\n",
    "hdj{m>838:A,pv}\n",
    "\n",
    "{x=787,m=2655,a=1222,s=2876}\n",
    "{x=1679,m=44,a=2067,s=496}\n",
    "{x=2036,m=264,a=79,s=2244}\n",
    "{x=2461,m=1339,a=466,s=291}\n",
    "{x=2127,m=1623,a=2188,s=1013}\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# NOTE: come back and do this in a graph theoretic way in the future\n",
    "def parse(inp):\n",
    "    flows,raw_parts = [half.split(\"\\n\") for half in inp.strip().split(\"\\n\\n\")]\n",
    "    workflows = defaultdict()\n",
    "    for flow in flows:\n",
    "        # px{a<2006:qkq,m>2090:A,rfg}\n",
    "        label, rules = flow[:-1].split(\"{\")\n",
    "        tmp = []\n",
    "        for rule in rules.split(\",\"):\n",
    "            if \":\" in rule:\n",
    "                regex = re.search(r\"(?P<categ>.*)(?P<comp>[><])(?P<quant>[0-9]+):(?P<nxt>.*)\", rule)\n",
    "                tmp.append([regex.group(\"categ\"), regex.group(\"comp\"), int(regex.group(\"quant\")), regex.group(\"nxt\")])\n",
    "            else:\n",
    "                tmp.append([rule])\n",
    "        workflows[label] = tmp\n",
    "    \n",
    "    parts = defaultdict(lambda: defaultdict())\n",
    "    for i, part in enumerate(raw_parts):\n",
    "        for categ in part[1:-1].split(\",\"):\n",
    "            cat, quant = categ.split(\"=\")\n",
    "            parts[i][cat] = int(quant)\n",
    "    \n",
    "    return workflows, parts\n",
    "\n",
    "def checkPart(workflows, part):\n",
    "    currLabel = \"in\"\n",
    "    while True:\n",
    "        if currLabel == 'A':\n",
    "            return 1\n",
    "        if currLabel == 'R':\n",
    "            return 0\n",
    "        for flow in workflows[currLabel]:\n",
    "            if flow == \"A\": \n",
    "                return 1\n",
    "            if flow == \"R\":\n",
    "                return 0\n",
    "            if len(flow) == 1:\n",
    "                currLabel = flow[0]\n",
    "                break\n",
    "            categ, comp, quant, nxt = flow\n",
    "            #print(flow, part)\n",
    "            if (comp == \">\" and part[categ] > quant) or (comp == \"<\" and part[categ] < quant):\n",
    "                currLabel = nxt\n",
    "                break\n",
    "            currLabel = nxt\n",
    "\n",
    "def p1(inp):\n",
    "    W, P = parse(inp)\n",
    "    res = 0\n",
    "    for idx in P:\n",
    "        #print(P[idx])\n",
    "        if checkPart(W, P[idx]):\n",
    "            res += P[idx]['x'] + P[idx]['m'] + P[idx]['a'] + P[idx]['s']\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19114"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected output: 19114\n",
    "p1(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353046"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseP2(inp):\n",
    "    flows,_ = [half.split(\"\\n\") for half in inp.strip().split(\"\\n\\n\")]\n",
    "    workflows = defaultdict()\n",
    "    for flow in flows:\n",
    "        # px{a<2006:qkq,m>2090:A,rfg}\n",
    "        label, rules = flow[:-1].split(\"{\")\n",
    "        tmp = []\n",
    "        for rule in rules.split(\",\"):\n",
    "            if \":\" in rule:\n",
    "                regex = re.search(r\"(?P<categ>.*)(?P<comp>[><])(?P<quant>[0-9]+):(?P<nxt>.*)\", rule)\n",
    "                tmp.append([regex.group(\"categ\"), regex.group(\"comp\"), int(regex.group(\"quant\")), regex.group(\"nxt\")])\n",
    "            else:\n",
    "                tmp.append([rule])\n",
    "        workflows[label] = tmp\n",
    "    \n",
    "    return workflows\n",
    "\n",
    "def split_ranges(uncertain):\n",
    "    acceptedRanges = []\n",
    "    rejectedRanges = []\n",
    "    \n",
    "\n",
    "\n",
    "def p2(inp):\n",
    "    workflows = parseP2(inp)\n",
    "    uncertainRanges = [([1,4000], [1,4000], [1,4000], [1,4000])]\n",
    "    return split_ranges(uncertainRanges)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
